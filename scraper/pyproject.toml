[project]
name = "sports-data-scraper"
version = "0.1.0"
description = "Sports data ingestion service for Scroll Down Sports."
requires-python = ">=3.11"
dependencies = [
  "pydantic>=2.8.0,<3.0.0",
  "pydantic-settings>=2.5.0,<3.0.0",
  "sqlalchemy>=2.0.0,<3.0.0",
  "psycopg[binary]>=3.2.0,<4.0.0",
  "alembic>=1.13.0,<2.0.0",
  "httpx>=0.27.0,<0.29.0",
  "beautifulsoup4>=4.12.0,<5.0.0",
  "lxml>=5.3.0,<7.0.0",
  "structlog>=24.1.0,<26.0.0",
  "celery>=5.4.0,<6.0.0",
  "redis>=5.0.0,<8.0.0",
  "tenacity>=9.0.0,<10.0.0",
  "playwright>=1.47.0,<2.0.0",
]

[tool.uv]
dev-dependencies = [
  "black>=24.8.0,<25.0.0",
  "ruff>=0.7.0,<0.8.0",
  "pytest>=8.3.2,<9.0.0",
  "pytest-cov>=4.1.0,<6.0.0",
  "mypy>=1.11.0,<2.0.0",
  "types-beautifulsoup4>=4.12.0,<5.0.0",
]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
addopts = [
  "--cov=sports_scraper",
  "--cov-report=term-missing",
  "--cov-report=html:coverage_html",
  "--cov-fail-under=80",
]

[tool.coverage.run]
source = ["sports_scraper"]
omit = [
  # Celery infrastructure
  "sports_scraper/celery_app.py",
  "sports_scraper/jobs/*",
  "sports_scraper/validate_env.py",
  "sports_scraper/__init__.py",
  # Social scraping (requires external X API)
  "sports_scraper/social/*",
  # Web scrapers (require HTTP mocking infrastructure)
  "sports_scraper/scrapers/*",
  # Database connection module
  "sports_scraper/db.py",
  # Services - orchestration code tested via integration tests
  "sports_scraper/services/*",
]

[tool.coverage.report]
exclude_lines = [
  "pragma: no cover",
  "if TYPE_CHECKING:",
  "raise NotImplementedError",
  "@abstractmethod",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["sports_scraper"]

